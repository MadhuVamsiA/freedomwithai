## How to use LLM models locally

1. Install the required libraries by using the requirements.txt file.
2. Check the huggingface models and use the model based on your requirement. https://huggingface.co/models
3. In the code we are using one of text2text generation model called "google/flan-t5-large"
4. Create a pipeline.
5. Use the model locally.

